{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.datasets import MOABBDataset\n",
    "from braindecode.preprocessing import preprocess, Preprocessor\n",
    "dataset = MOABBDataset(dataset_name=\"BNCI2014_001\", subject_ids=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joel\\AppData\\Roaming\\Python\\Python311\\site-packages\\braindecode\\preprocessing\\preprocess.py:55: UserWarning: Preprocessing choices with lambda functions cannot be saved.\n",
      "  warn('Preprocessing choices with lambda functions cannot be saved.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<braindecode.datasets.moabb.MOABBDataset at 0x270c20e8050>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from braindecode.preprocessing import (\n",
    "    exponential_moving_standardize,\n",
    "    preprocess,\n",
    "    Preprocessor,\n",
    ")\n",
    "\n",
    "low_cut_hz = 4.0  # low cut frequency for filtering\n",
    "high_cut_hz = 38.0  # high cut frequency for filtering\n",
    "# Parameters for exponential moving standardization\n",
    "factor_new = 1e-3\n",
    "init_block_size = 1000\n",
    "\n",
    "preprocessors = [\n",
    "    Preprocessor(\"pick_types\", eeg=True, meg=False, stim=False),  # Keep EEG sensors\n",
    "    Preprocessor(\n",
    "        lambda data, factor: np.multiply(data, factor),  # Convert from V to uV\n",
    "        factor=1e6,\n",
    "    ),\n",
    "    Preprocessor(\"filter\", l_freq=low_cut_hz, h_freq=high_cut_hz),  # Bandpass filter\n",
    "    Preprocessor(\n",
    "        exponential_moving_standardize,  # Exponential moving standardization\n",
    "        factor_new=factor_new,\n",
    "        init_block_size=init_block_size,\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Preprocess the data\n",
    "preprocess(dataset, preprocessors, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n"
     ]
    }
   ],
   "source": [
    "from braindecode.preprocessing import create_windows_from_events\n",
    "\n",
    "trial_start_offset_seconds = -0.5\n",
    "# Extract sampling frequency, check that they are same in all datasets\n",
    "sfreq = dataset.datasets[0].raw.info[\"sfreq\"]\n",
    "assert all([ds.raw.info[\"sfreq\"] == sfreq for ds in dataset.datasets])\n",
    "# Calculate the window start offset in samples.\n",
    "trial_start_offset_samples = int(trial_start_offset_seconds * sfreq)\n",
    "\n",
    "# Create windows using braindecode function for this. It needs parameters to\n",
    "# define how windows should be used.\n",
    "windows_dataset = create_windows_from_events(\n",
    "    dataset,\n",
    "    trial_start_offset_samples=trial_start_offset_samples,\n",
    "    trial_stop_offset_samples=0,\n",
    "    preload=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted = windows_dataset.split(\"session\")\n",
    "train_set = splitted['0train']  # Session train\n",
    "test_set = splitted['1test']  # Session evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)        Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "============================================================================================================================================\n",
      "ShallowFBCSPNet (ShallowFBCSPNet)        [1, 22, 1125]             [1, 4]                    --                        --\n",
      "├─Ensure4d (ensuredims): 1-1             [1, 22, 1125]             [1, 22, 1125, 1]          --                        --\n",
      "├─Rearrange (dimshuffle): 1-2            [1, 22, 1125, 1]          [1, 1, 1125, 22]          --                        --\n",
      "├─CombinedConv (conv_time_spat): 1-3     [1, 1, 1125, 22]          [1, 40, 1101, 1]          36,240                    --\n",
      "├─BatchNorm2d (bnorm): 1-4               [1, 40, 1101, 1]          [1, 40, 1101, 1]          80                        --\n",
      "├─Expression (conv_nonlin_exp): 1-5      [1, 40, 1101, 1]          [1, 40, 1101, 1]          --                        --\n",
      "├─AvgPool2d (pool): 1-6                  [1, 40, 1101, 1]          [1, 40, 69, 1]            --                        [75, 1]\n",
      "├─Expression (pool_nonlin_exp): 1-7      [1, 40, 69, 1]            [1, 40, 69, 1]            --                        --\n",
      "├─Dropout (drop): 1-8                    [1, 40, 69, 1]            [1, 40, 69, 1]            --                        --\n",
      "├─Sequential (final_layer): 1-9          [1, 40, 69, 1]            [1, 4]                    --                        --\n",
      "│    └─Conv2d (conv_classifier): 2-1     [1, 40, 69, 1]            [1, 4, 1, 1]              11,044                    [69, 1]\n",
      "│    └─Expression (squeeze): 2-2         [1, 4, 1, 1]              [1, 4]                    --                        --\n",
      "============================================================================================================================================\n",
      "Total params: 47,364\n",
      "Trainable params: 47,364\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 0.01\n",
      "============================================================================================================================================\n",
      "Input size (MB): 0.10\n",
      "Forward/backward pass size (MB): 0.35\n",
      "Params size (MB): 0.04\n",
      "Estimated Total Size (MB): 0.50\n",
      "============================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models import ShallowFBCSPNet\n",
    "\n",
    "n_classes = 4\n",
    "classes = list(range(n_classes))\n",
    "# Extract number of chans and time steps from dataset\n",
    "n_channels = windows_dataset[0][0].shape[0]\n",
    "input_window_samples = windows_dataset[0][0].shape[1]\n",
    "\n",
    "model = ShallowFBCSPNet(\n",
    "    n_channels,\n",
    "    n_classes,\n",
    "    n_times=input_window_samples,\n",
    "    final_conv_length=\"auto\",\n",
    "    add_log_softmax=False,\n",
    ")\n",
    "\n",
    "# Display torchinfo table describing the model\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_accuracy    train_loss      lr     dur\n",
      "-------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.3299\u001b[0m       \u001b[32m-0.4043\u001b[0m  0.0006  1.7421\n",
      "      2            0.3299       \u001b[32m-2.1012\u001b[0m  0.0006  1.5971\n",
      "      3            \u001b[36m0.3403\u001b[0m       \u001b[32m-3.7873\u001b[0m  0.0006  2.0554\n",
      "      4            0.3368       \u001b[32m-5.3624\u001b[0m  0.0005  2.1362\n",
      "      5            \u001b[36m0.3576\u001b[0m       \u001b[32m-7.2175\u001b[0m  0.0004  1.6454\n",
      "      6            \u001b[36m0.3750\u001b[0m       \u001b[32m-8.4774\u001b[0m  0.0003  1.8449\n",
      "      7            \u001b[36m0.3785\u001b[0m       \u001b[32m-9.0368\u001b[0m  0.0002  1.8034\n",
      "      8            \u001b[36m0.4201\u001b[0m       \u001b[32m-9.6362\u001b[0m  0.0001  1.9087\n",
      "      9            \u001b[36m0.4410\u001b[0m      \u001b[32m-10.1487\u001b[0m  0.0000  1.7595\n",
      "     10            \u001b[36m0.4618\u001b[0m      \u001b[32m-10.1759\u001b[0m  0.0000  1.9310\n",
      "Test acc: 36.81%\n"
     ]
    }
   ],
   "source": [
    "from skorch.callbacks import LRScheduler\n",
    "\n",
    "from braindecode import EEGClassifier\n",
    "\n",
    "lr = 0.0625 * 0.01\n",
    "weight_decay = 0\n",
    "batch_size = 64\n",
    "n_epochs = 10\n",
    "\n",
    "clf = EEGClassifier(\n",
    "    model,\n",
    "    criterion=torch.nn.NLLLoss,\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    train_split=None,\n",
    "    optimizer__lr=lr,\n",
    "    optimizer__weight_decay=weight_decay,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[\n",
    "        \"accuracy\",\n",
    "        (\"lr_scheduler\", LRScheduler(\"CosineAnnealingLR\", T_max=n_epochs - 1)),\n",
    "    ],\n",
    "    classes=classes,\n",
    "    max_epochs=n_epochs,\n",
    ")\n",
    "# Model training for a specified number of epochs. `y` is None as it is already supplied\n",
    "# in the dataset.\n",
    "clf.fit(train_set, y=None)\n",
    "\n",
    "# evaluated the model after training\n",
    "y_test = test_set.get_metadata().target\n",
    "test_acc = clf.score(test_set, y=y_test)\n",
    "print(f\"Test acc: {(test_acc * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 2 0 0 1 0 3 2 1 2 2 1 1 0 1 1 2 0 1 1 2 3 2 2 1 3 1 1 0 0 0 1 1 2\n",
      " 0 1 0 0 0 1 0 0 1 3 1 1 3 2 2 1 2 0 2 1 0 2 2 2 1 2 0 2 0 3 1 2 2 0 0 1 1\n",
      " 1 1 2 0 2 2 2 2 1 1 1 0 1 3 0 1 1 1 0 1 2 0 2 1 0 2 1 0 2 1 1 0 1 0 3 2 0\n",
      " 2 0 2 1 1 2 1 1 1 2 0 0 2 2 2 1 0 2 1 0 2 1 2 1 2 1 1 1 2 0 0 2 1 2 2 1 0\n",
      " 0 0 1 1 0 2 0 0 1 1 1 0 1 3 1 0 0 1 2 0 0 2 1 1 2 2 2 1 0 1 1 2 1 2 0 0 3\n",
      " 3 0 2 0 1 2 0 1 2 1 0 1 2 1 1 1 0 1 2 2 1 1 1 0 0 1 1 0 0 1 0 1 1 2 1 1 0\n",
      " 1 3 2 1 0 1 1 0 0 1 1 2 0 1 1 1 0 0 1 1 3 0 1 2 1 2 0 2 3 1 1 2 1 0 2 1 1\n",
      " 1 2 0 0 0 0 1 2 0 1 2 3 1 0 1 1 2 1 0 2 0 1 0 0 1 0 2 2 0]\n"
     ]
    }
   ],
   "source": [
    "predicted = clf.predict(test_set)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_set.get_metadata().target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
