{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.datasets import MOABBDataset\n",
    "from braindecode.preprocessing import preprocess, Preprocessor\n",
    "\n",
    "\n",
    "dataset = MOABBDataset(dataset_name=\"BNCI2014_001\", subject_ids=[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joel\\AppData\\Roaming\\Python\\Python311\\site-packages\\braindecode\\preprocessing\\preprocess.py:55: UserWarning: Preprocessing choices with lambda functions cannot be saved.\n",
      "  warn('Preprocessing choices with lambda functions cannot be saved.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<braindecode.datasets.moabb.MOABBDataset at 0x242878e80d0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from braindecode.preprocessing import (\n",
    "    exponential_moving_standardize,\n",
    "    preprocess,\n",
    "    Preprocessor,\n",
    ")\n",
    "\n",
    "low_cut_hz = 4.0  # low cut frequency for filtering\n",
    "high_cut_hz = 38.0  # high cut frequency for filtering\n",
    "# Parameters for exponential moving standardization\n",
    "factor_new = 1e-3\n",
    "init_block_size = 1000\n",
    "\n",
    "preprocessors = [\n",
    "    Preprocessor(\"pick_types\", eeg=True, meg=False, stim=False),  # Keep EEG sensors\n",
    "    Preprocessor(\n",
    "        lambda data, factor: np.multiply(data, factor),  # Convert from V to uV\n",
    "        factor=1e6,\n",
    "    ),\n",
    "    Preprocessor(\"filter\", l_freq=low_cut_hz, h_freq=high_cut_hz),  # Bandpass filter\n",
    "    Preprocessor(\n",
    "        exponential_moving_standardize,  # Exponential moving standardization\n",
    "        factor_new=factor_new,\n",
    "        init_block_size=init_block_size,\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Preprocess the data\n",
    "preprocess(dataset, preprocessors, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<braindecode.datasets.moabb.MOABBDataset at 0x242878e80d0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessors = [\n",
    "    Preprocessor('pick_types', eeg=True, meg=False, stim=True),\n",
    "    Preprocessor('resample', sfreq=100)\n",
    "]\n",
    "# Preprocess the data\n",
    "preprocess(dataset, preprocessors, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n"
     ]
    }
   ],
   "source": [
    "from braindecode.preprocessing import create_windows_from_events\n",
    "\n",
    "trial_start_offset_seconds = -0.5\n",
    "# Extract sampling frequency, check that they are same in all datasets\n",
    "sfreq = dataset.datasets[0].raw.info[\"sfreq\"]\n",
    "assert all([ds.raw.info[\"sfreq\"] == sfreq for ds in dataset.datasets])\n",
    "# Calculate the window start offset in samples.\n",
    "trial_start_offset_samples = int(trial_start_offset_seconds * sfreq)\n",
    "\n",
    "# Create windows using braindecode function for this. It needs parameters to\n",
    "# define how windows should be used.\n",
    "windows_dataset = create_windows_from_events(\n",
    "    dataset,\n",
    "    trial_start_offset_samples=trial_start_offset_samples,\n",
    "    trial_stop_offset_samples=0,\n",
    "    preload=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted = windows_dataset.split(\"session\")\n",
    "train_set = splitted['0train']  # Session train\n",
    "test_set = splitted['1test']  # Session evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)        Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "============================================================================================================================================\n",
      "ShallowFBCSPNet (ShallowFBCSPNet)        [1, 22, 450]              [1, 4]                    --                        --\n",
      "├─Ensure4d (ensuredims): 1-1             [1, 22, 450]              [1, 22, 450, 1]           --                        --\n",
      "├─Rearrange (dimshuffle): 1-2            [1, 22, 450, 1]           [1, 1, 450, 22]           --                        --\n",
      "├─CombinedConv (conv_time_spat): 1-3     [1, 1, 450, 22]           [1, 40, 426, 1]           36,240                    --\n",
      "├─BatchNorm2d (bnorm): 1-4               [1, 40, 426, 1]           [1, 40, 426, 1]           80                        --\n",
      "├─Expression (conv_nonlin_exp): 1-5      [1, 40, 426, 1]           [1, 40, 426, 1]           --                        --\n",
      "├─AvgPool2d (pool): 1-6                  [1, 40, 426, 1]           [1, 40, 24, 1]            --                        [75, 1]\n",
      "├─Expression (pool_nonlin_exp): 1-7      [1, 40, 24, 1]            [1, 40, 24, 1]            --                        --\n",
      "├─Dropout (drop): 1-8                    [1, 40, 24, 1]            [1, 40, 24, 1]            --                        --\n",
      "├─Sequential (final_layer): 1-9          [1, 40, 24, 1]            [1, 4]                    --                        --\n",
      "│    └─Conv2d (conv_classifier): 2-1     [1, 40, 24, 1]            [1, 4, 1, 1]              3,844                     [24, 1]\n",
      "│    └─LogSoftmax (logsoftmax): 2-2      [1, 4, 1, 1]              [1, 4, 1, 1]              --                        --\n",
      "│    └─Expression (squeeze): 2-3         [1, 4, 1, 1]              [1, 4]                    --                        --\n",
      "============================================================================================================================================\n",
      "Total params: 40,164\n",
      "Trainable params: 40,164\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 0.00\n",
      "============================================================================================================================================\n",
      "Input size (MB): 0.04\n",
      "Forward/backward pass size (MB): 0.14\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 0.19\n",
      "============================================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joel\\AppData\\Roaming\\Python\\Python311\\site-packages\\braindecode\\models\\base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models import ShallowFBCSPNet\n",
    "\n",
    "cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n",
    "device = \"cuda\" if cuda else \"cpu\"\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed = 20200220\n",
    "set_random_seeds(seed=seed, cuda=cuda)\n",
    "\n",
    "n_classes = 4\n",
    "classes = list(range(n_classes))\n",
    "# Extract number of chans and time steps from dataset\n",
    "n_channels = windows_dataset[0][0].shape[0]\n",
    "input_window_samples = windows_dataset[0][0].shape[1]\n",
    "\n",
    "model = ShallowFBCSPNet(\n",
    "    n_channels,\n",
    "    n_classes,\n",
    "    n_times=input_window_samples,\n",
    "    final_conv_length=\"auto\",\n",
    ")\n",
    "\n",
    "# Display torchinfo table describing the model\n",
    "print(model)\n",
    "\n",
    "# Send model to GPU\n",
    "if cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_accuracy    train_loss      lr     dur\n",
      "-------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.8785\u001b[0m        \u001b[32m0.7475\u001b[0m  0.0006  0.6693\n",
      "      2            0.8715        \u001b[32m0.6937\u001b[0m  0.0006  0.6391\n",
      "      3            \u001b[36m0.8819\u001b[0m        \u001b[32m0.6790\u001b[0m  0.0006  0.4959\n",
      "      4            \u001b[36m0.8993\u001b[0m        \u001b[32m0.6036\u001b[0m  0.0006  0.4515\n",
      "      5            \u001b[36m0.9167\u001b[0m        0.6354  0.0006  0.4696\n",
      "      6            \u001b[36m0.9306\u001b[0m        \u001b[32m0.5919\u001b[0m  0.0006  0.5745\n",
      "      7            \u001b[36m0.9340\u001b[0m        \u001b[32m0.5205\u001b[0m  0.0006  0.6547\n",
      "      8            \u001b[36m0.9444\u001b[0m        \u001b[32m0.5116\u001b[0m  0.0006  0.6027\n",
      "      9            0.9340        \u001b[32m0.4739\u001b[0m  0.0006  0.6232\n",
      "     10            0.9167        \u001b[32m0.4681\u001b[0m  0.0006  0.6467\n",
      "     11            0.9167        \u001b[32m0.4313\u001b[0m  0.0006  0.6612\n",
      "     12            \u001b[36m0.9514\u001b[0m        \u001b[32m0.4178\u001b[0m  0.0006  0.7192\n",
      "     13            \u001b[36m0.9653\u001b[0m        \u001b[32m0.4125\u001b[0m  0.0005  0.7691\n",
      "     14            \u001b[36m0.9757\u001b[0m        \u001b[32m0.3888\u001b[0m  0.0005  1.0391\n",
      "     15            0.9757        \u001b[32m0.3712\u001b[0m  0.0005  0.7461\n",
      "     16            \u001b[36m0.9861\u001b[0m        0.3835  0.0005  0.7468\n",
      "     17            0.9792        \u001b[32m0.3645\u001b[0m  0.0005  0.5526\n",
      "     18            0.9792        \u001b[32m0.3470\u001b[0m  0.0005  0.5283\n",
      "     19            0.9861        \u001b[32m0.3402\u001b[0m  0.0004  0.8515\n",
      "     20            0.9861        \u001b[32m0.3086\u001b[0m  0.0004  0.5675\n",
      "     21            \u001b[36m0.9931\u001b[0m        0.3128  0.0004  0.5546\n",
      "     22            0.9931        0.3169  0.0004  0.6496\n",
      "     23            0.9931        \u001b[32m0.2816\u001b[0m  0.0004  0.7088\n",
      "     24            0.9931        \u001b[32m0.2721\u001b[0m  0.0003  0.7989\n",
      "     25            \u001b[36m0.9965\u001b[0m        0.2726  0.0003  0.6940\n",
      "     26            0.9965        \u001b[32m0.2640\u001b[0m  0.0003  0.6846\n",
      "     27            0.9965        \u001b[32m0.2636\u001b[0m  0.0003  0.8492\n",
      "     28            0.9965        \u001b[32m0.2511\u001b[0m  0.0003  0.7175\n",
      "     29            0.9965        \u001b[32m0.2404\u001b[0m  0.0002  1.0351\n",
      "     30            0.9965        \u001b[32m0.2311\u001b[0m  0.0002  0.6515\n",
      "     31            0.9965        0.2312  0.0002  0.6942\n",
      "     32            0.9965        \u001b[32m0.2250\u001b[0m  0.0002  0.5956\n",
      "     33            0.9965        0.2584  0.0002  0.8300\n",
      "     34            0.9965        0.2331  0.0002  0.8912\n",
      "     35            0.9965        0.2313  0.0001  0.6509\n",
      "     36            0.9965        0.2458  0.0001  0.6168\n",
      "     37            0.9965        \u001b[32m0.1975\u001b[0m  0.0001  0.6930\n",
      "     38            0.9965        0.2064  0.0001  0.6043\n",
      "     39            0.9965        0.2142  0.0001  0.6036\n",
      "     40            0.9965        0.2163  0.0001  0.8845\n",
      "     41            0.9965        0.1987  0.0001  0.7009\n",
      "     42            0.9965        0.2170  0.0000  1.1580\n",
      "     43            0.9965        0.2073  0.0000  1.3770\n",
      "     44            0.9965        0.1987  0.0000  0.8890\n",
      "     45            0.9965        0.2188  0.0000  0.7711\n",
      "     46            0.9965        0.2166  0.0000  0.7602\n",
      "     47            0.9965        0.2070  0.0000  0.7651\n",
      "     48            0.9965        0.2152  0.0000  0.9176\n",
      "     49            0.9965        0.2044  0.0000  0.6137\n",
      "     50            0.9965        0.2130  0.0000  0.7023\n",
      "Test acc: 54.86%\n"
     ]
    }
   ],
   "source": [
    "from skorch.callbacks import LRScheduler\n",
    "\n",
    "from braindecode import EEGClassifier\n",
    "\n",
    "lr = 0.0625 * 0.01\n",
    "weight_decay = 0\n",
    "batch_size = 64\n",
    "n_epochs = 50\n",
    "\n",
    "clf = EEGClassifier(\n",
    "    model,\n",
    "    criterion=torch.nn.NLLLoss,\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    train_split=None,\n",
    "    optimizer__lr=lr,\n",
    "    optimizer__weight_decay=weight_decay,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[\n",
    "        \"accuracy\",\n",
    "        (\"lr_scheduler\", LRScheduler(\"CosineAnnealingLR\", T_max=n_epochs - 1)),\n",
    "    ],\n",
    "    device=device,\n",
    "    classes=classes,\n",
    "    max_epochs=n_epochs,\n",
    ")\n",
    "# Model training for a specified number of epochs. `y` is None as it is already supplied\n",
    "# in the dataset.\n",
    "clf.fit(train_set, y=None)\n",
    "\n",
    "# evaluated the model after training\n",
    "y_test = test_set.get_metadata().target\n",
    "test_acc = clf.score(test_set, y=y_test)\n",
    "print(f\"Test acc: {(test_acc * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 0 2 3 1 3 2 3 2 3 2 1 3 0 3 3 0 1 0 2 0 0 3 3 2 0 3 3 2 0 1 2 2 1 2\n",
      " 3 1 1 0 3 3 0 3 0 3 0 0 3 1 2 3 1 0 0 1 0 1 1 2 3 2 0 1 3 3 3 2 2 3 3 1 0\n",
      " 3 2 3 0 2 1 2 3 0 3 2 3 1 3 2 0 2 3 3 2 1 3 2 2 3 2 1 1 1 3 2 3 1 3 3 1 3\n",
      " 2 3 3 2 0 2 0 2 3 2 3 1 2 2 3 3 0 0 0 3 3 3 1 3 2 0 3 1 2 2 0 3 1 2 3 2 3\n",
      " 2 3 2 1 3 2 0 3 0 1 1 3 2 3 1 3 0 2 0 3 1 2 3 0 3 2 0 3 1 2 1 0 2 2 1 1 3\n",
      " 3 0 0 0 1 2 0 2 2 2 0 0 2 0 3 2 0 1 1 2 0 3 2 3 3 0 0 3 2 2 3 2 2 1 1 0 0\n",
      " 1 0 2 2 2 0 1 0 2 0 3 0 0 1 0 0 2 0 0 1 3 2 3 2 2 0 3 2 3 2 2 0 2 3 0 2 2\n",
      " 1 2 3 3 0 3 2 2 0 2 2 3 2 0 3 2 2 1 3 3 3 2 3 0 3 0 0 2 3]\n",
      "<braindecode.datasets.base.BaseConcatDataset object at 0x000002428124C110>\n"
     ]
    }
   ],
   "source": [
    "all_preds = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,1,2,3,4,5,6,7,8,9,10,11]\n",
    "predicted = clf.predict(test_set)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
